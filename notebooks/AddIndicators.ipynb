{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('all_symbols.parquet')\n",
    "regime_df = pd.read_parquet('market_index.parquet')\n",
    "sector_df = pd.read_parquet('sector_index.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "\n",
    "def prep_regime_filter(regime_df, roc_col_name='regime_roc', mv_col_name='regime_ma',\n",
    "                       close_name='regime_close',\n",
    "                       ma_period=200,\n",
    "                       roc_period=45):\n",
    "    regime_df.loc[:, roc_col_name] = ta.momentum.ROCIndicator(regime_df.adj_close, n=roc_period).roc()\n",
    "    regime_df.loc[:, mv_col_name] = regime_df.set_index(\n",
    "        'Date'\n",
    "    ).adj_close.rolling('%dd' % ma_period, min_periods=1).mean().values\n",
    "    regime_df.loc[:, close_name] = regime_df.adj_close\n",
    "    return regime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime_df = prep_regime_filter(regime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_df = sector_df.groupby('sector').apply(lambda x: prep_regime_filter(x, roc_col_name='sector_roc',\n",
    "                                                                     mv_col_name='sector_ma',\n",
    "                                                                     close_name='sector_close'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(regime_df[['Date', 'regime_close', 'regime_ma']], on='Date', how='left')\n",
    "df = df.merge(sector_df[['Date', 'sector', 'sector_close', 'sector_ma']], on=['Date', 'sector'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "import numpy as np\n",
    "\n",
    "def mean_atr(df, atr_period=14):\n",
    "    df.loc[:, 'last_close'] = df.adj_close.shift(1)\n",
    "    atr_high = np.maximum(df.high_adj, df.last_close)\n",
    "    atr_low = np.minimum(df.high_adj, df.last_close) \n",
    "    atr = atr_high - atr_low\n",
    "    return atr, atr.ewm(span=atr_period, adjust=False).mean()\n",
    "\n",
    "def mean_close_diff_norm(close, ma):\n",
    "    return (close - ma) / ma\n",
    "\n",
    "def manual_mfi(df, period):\n",
    "    mfi_df = df[['adj_close', 'Date', 'Volume']].set_index('Date')\n",
    "    mfi_df.loc[:, 'prev_close'] = mfi_df.adj_close.shift(1)\n",
    "    mfi_df.loc[:, 'perc_change'] = (mfi_df.prev_close - mfi_df.adj_close).abs() / mfi_df.adj_close\n",
    "    up_index = mfi_df.adj_close > mfi_df.prev_close\n",
    "    down_index = mfi_df.adj_close < mfi_df.prev_close\n",
    "    mfi_df.loc[:, 'avg_up'] = 0\n",
    "    mfi_df.loc[:, 'avg_down'] = 0\n",
    "    mfi_df.loc[up_index, 'avg_up'] = mfi_df.loc[up_index, 'perc_change'] * mfi_df.loc[up_index, 'Volume']\n",
    "    mfi_df.loc[down_index, 'avg_down'] = mfi_df.loc[down_index, 'perc_change'] * mfi_df.loc[down_index, 'Volume']\n",
    "    mfi_df.loc[:, 'avg_up'] = mfi_df.loc[:, 'avg_up'].ewm(alpha=1.0 / period, adjust=False).mean()\n",
    "    mfi_df.loc[:, 'avg_down'] = mfi_df.loc[:, 'avg_down'].ewm(alpha=1.0 / period, adjust=False).mean()\n",
    "    mfi = (100.0 - (100.0 / (1 + (mfi_df.avg_up / mfi_df.avg_down)))).values\n",
    "    return mfi\n",
    "\n",
    "\n",
    "def generate_ta_features(sym_df, rsi_period=5, roc_period=45, roc_short_period=4,\n",
    "                         roc_long_period=(20 * 5), break_out_period=(20 * 5),\n",
    "                         fut_roc_period=5, mfi_period=5,\n",
    "                         sto_period=14, atr_period=14, volitility_short_period=2, bba_period=20,\n",
    "                         dch_period=20, ma_period=200,\n",
    "                         macd_fast=12, macd_slow=26, macd_sig=9, bb_wide_dev=3, bb_slim_dev=1):\n",
    "    sym_df = sym_df.sort_values('Date')\n",
    "    sym_df.loc[:, 'mv_avg'] = sym_df.set_index(\n",
    "        'Date'\n",
    "    ).adj_close.rolling('%dd' % ma_period, min_periods=1).mean().values\n",
    "    sym_df.loc[:, '200_day_high'] = sym_df.set_index(\n",
    "        'Date'\n",
    "    ).adj_close.rolling(\n",
    "        '%dd' % break_out_period, min_periods=1\n",
    "    ).max().shift().values\n",
    "    rsi = ta.momentum.RSIIndicator(close=sym_df.adj_close, n=rsi_period).rsi()\n",
    "    roc = ta.momentum.ROCIndicator(sym_df.adj_close, n=roc_period).roc()\n",
    "    roc_long = ta.momentum.ROCIndicator(sym_df.adj_close, n=roc_long_period).roc()\n",
    "    roc_short = ta.momentum.ROCIndicator(sym_df.adj_close, n=roc_short_period).roc()\n",
    "    roc_fut = ta.momentum.ROCIndicator(sym_df.adj_close, n=fut_roc_period).roc()\n",
    "    mfi = ta.volume.MFIIndicator(\n",
    "        high=sym_df.adj_high, low=sym_df.adj_low,\n",
    "        close=sym_df.adj_close, volume=sym_df.Volume,\n",
    "        n=mfi_period\n",
    "    ).money_flow_index()\n",
    "    macd_diff = ta.trend.macd_diff(\n",
    "        sym_df.adj_close, n_slow=macd_slow, n_fast=macd_fast, n_sign=macd_sig\n",
    "    )\n",
    "    sto = ta.momentum.StochasticOscillator(high=sym_df.adj_high, low=sym_df.adj_low, close=sym_df.adj_close,\n",
    "                                     n=sto_period).stoch_signal()\n",
    "    bb = ta.volatility.BollingerBands(close=sym_df.adj_close, n=bba_period)\n",
    "    bb_high = bb.bollinger_hband()\n",
    "    bb_low = bb.bollinger_lband()\n",
    "    bba = bb_high - bb_low\n",
    "    bb_wide = ta.volatility.BollingerBands(close=sym_df.adj_close, n=bba_period, ndev=bb_wide_dev)\n",
    "    bb_wide_high = bb_wide.bollinger_hband()\n",
    "    bb_slim = ta.volatility.BollingerBands(close=sym_df.adj_close, n=bba_period, ndev=bb_slim_dev)\n",
    "    bb_slim_low = bb_slim.bollinger_lband()\n",
    "    dc = ta.volatility.DonchianChannel(high=sym_df.adj_high, low=sym_df.adj_low, close=sym_df.adj_close, n=dch_period)\n",
    "    dc_high = dc.donchian_channel_hband()\n",
    "    dc_low = dc.donchian_channel_lband()\n",
    "    dch = dc_high - dc_low\n",
    "    sym_df.loc[:, 'rsi'] = rsi\n",
    "    sym_df.loc[:, 'roc'] = roc\n",
    "    sym_df.loc[:, 'roc_long'] = roc_long\n",
    "    sym_df.loc[:, 'roc_short'] = roc_short\n",
    "    sym_df.loc[:, 'fut_roc'] = roc_fut.shift(-fut_roc_period)\n",
    "    sym_df.loc[:, 'mfi'] = mfi\n",
    "    sym_df.loc[:, 'sto'] = sto\n",
    "    sym_df.loc[:, 'bba'] = bba\n",
    "    sym_df.loc[:, 'bb_high'] = bb_high\n",
    "    sym_df.loc[:, 'bb_low'] = bb_low\n",
    "    sym_df.loc[:, 'bb_wide_high'] = bb_wide_high\n",
    "    sym_df.loc[:, 'bb_slim_low'] = bb_slim_low\n",
    "    sym_df.loc[:, 'dch'] = dch\n",
    "    sym_df.loc[:, 'bba_norm'] = bba / sym_df.adj_close\n",
    "    sym_df.loc[:, 'dch_norm'] = dch / sym_df.adj_close\n",
    "    sym_df.loc[:, 'ma_diff_norm'] = mean_close_diff_norm(sym_df.adj_close, sym_df.mv_avg)\n",
    "    sym_df.loc[:, 'regime_ma_diff_norm'] = mean_close_diff_norm(sym_df.regime_close, sym_df.regime_ma)\n",
    "    sym_df.loc[:, 'sector_ma_diff_norm'] = mean_close_diff_norm(sym_df.sector_close, sym_df.sector_ma)\n",
    "    volatility_base = (sym_df.adj_close.diff() / sym_df.adj_close.shift(1)).abs()\n",
    "    sym_df.loc[:, 'volatility'] = volatility_base.ewm(span=atr_period, adjust=False).mean()\n",
    "    sym_df.loc[:, 'volatility_short'] = volatility_base.ewm(span=volitility_short_period, adjust=False).mean()\n",
    "    sym_df.loc[:, 'directional_strength'] = -(sym_df.adj_close.diff() / sym_df.adj_close.shift(1)).ewm(span=atr_period,\n",
    "                                                                                                      adjust=False).mean()\n",
    "    sym_df.loc[:, 'macd_diff'] = macd_diff\n",
    "    return sym_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_feats = df.groupby('symbol').apply(generate_ta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_quarter(date):\n",
    "    quarter = np.ceil(date.dt.month / 3)\n",
    "    return quarter\n",
    "\n",
    "def get_prev_quart_and_num(year, quarter):\n",
    "    prev_quarter = quarter - 1\n",
    "    year_diff = np.zeros(year.shape[0])\n",
    "    year_diff[prev_quarter == 0] = -1\n",
    "    prev_year = year - year_diff\n",
    "    prev_quarter.loc[prev_quarter == 0] = 4\n",
    "    return prev_year, prev_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_feats.loc[:, 'quarter'] = get_quarter(ta_feats['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_year, prev_quarter =  get_prev_quart_and_num(ta_feats['Date'].dt.year, ta_feats.quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_feats.loc[:, 'prev_year'] = prev_year\n",
    "ta_feats.loc[:, 'prev_quarter'] = prev_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_df = pd.read_parquet('fundamentals.parquet')\n",
    "fundamental_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_cols = ['CommonStockSharesOutstanding', 'EarningsPerShareBasic',\n",
    "                    'year', 'quarter', 'symbol']\n",
    "join_df = ta_feats.reset_index(drop=True).merge(\n",
    "    fundamental_df[fundamental_cols].drop_duplicates(),\n",
    "    left_on=['prev_year', 'prev_quarter', 'symbol'],\n",
    "    right_on=['year', 'quarter', 'symbol'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = join_df.sort_values(['symbol', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_outstanding_shares(sym_df):\n",
    "    sym_df.loc[:, 'CommonStockSharesOutstanding'] =  sym_df['CommonStockSharesOutstanding'].fillna(method='ffill')\n",
    "    return sym_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = join_df.groupby('symbol').apply(fill_outstanding_shares).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.loc[:, 'MarketCap'] = join_df.CommonStockSharesOutstanding * join_df.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.to_parquet('ta_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "ta_data = pd.read_parquet('ta_data.parquet')\n",
    "fund_df = pd.read_parquet('fundamentals.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import datetime as dt\n",
    "\n",
    "ta_data.loc[ta_data.CommonStockSharesOutstanding.isnull() & (ta_data['Date'] > dt.datetime(2020, 12, 1))].symbol.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta_data['Date'].dt.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ta_data.loc[ta_data.EarningsPerShareBasic.isnull() & (ta_data['Date'] > dt.datetime(2020, 12, 1))].symbol.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorted(ta_data.loc[ta_data.CommonStockSharesOutstanding.isnull() & (ta_data['Date'] > dt.datetime(2020, 12, 1))].symbol.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fund_df.loc[(fund_df.year == 2020) & (fund_df.quarter == 3) & (fund_df.symbol == 'MGM')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fund_df.loc[(fund_df.year == 2020) & (fund_df.quarter == 3) & (fund_df.symbol == 'AAPL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function logging.info(msg, *args, **kwargs)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.info('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure out if there is aything you can do to reduce non null values in fundamental columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
